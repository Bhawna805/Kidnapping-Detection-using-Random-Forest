{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE/UT</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>Purpose</th>\n",
       "      <th>Total No. of cases reported</th>\n",
       "      <th>Male upto 10 years</th>\n",
       "      <th>Female upto 10 years</th>\n",
       "      <th>Male 10-15 years</th>\n",
       "      <th>Female 10-15 years</th>\n",
       "      <th>Male 15-18 years</th>\n",
       "      <th>Female 15-18 years</th>\n",
       "      <th>...</th>\n",
       "      <th>Female 30-50 years</th>\n",
       "      <th>Male above 50 years</th>\n",
       "      <th>Female above 50 years</th>\n",
       "      <th>Total Male</th>\n",
       "      <th>Total Female</th>\n",
       "      <th>Grand Total</th>\n",
       "      <th>Male below 18</th>\n",
       "      <th>Female below 18</th>\n",
       "      <th>Number of children</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>2001</td>\n",
       "      <td>For Adoption</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>2001</td>\n",
       "      <td>For Begging</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>2001</td>\n",
       "      <td>For Camel racing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>2001</td>\n",
       "      <td>For Illicit intercourse</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>2001</td>\n",
       "      <td>For marriage</td>\n",
       "      <td>339</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>164</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>332</td>\n",
       "      <td>339</td>\n",
       "      <td>1</td>\n",
       "      <td>237</td>\n",
       "      <td>238</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         STATE/UT  YEAR                  Purpose  Total No. of cases reported  \\\n",
       "0  Andhra Pradesh  2001             For Adoption                            8   \n",
       "1  Andhra Pradesh  2001              For Begging                            2   \n",
       "2  Andhra Pradesh  2001         For Camel racing                            0   \n",
       "3  Andhra Pradesh  2001  For Illicit intercourse                           78   \n",
       "4  Andhra Pradesh  2001             For marriage                          339   \n",
       "\n",
       "   Male upto 10 years  Female upto 10 years  Male 10-15 years  \\\n",
       "0                   3                     1                 0   \n",
       "1                   0                     0                 2   \n",
       "2                   0                     0                 0   \n",
       "3                   0                     2                 0   \n",
       "4                   0                     0                 0   \n",
       "\n",
       "   Female 10-15 years  Male 15-18 years  Female 15-18 years  ...  \\\n",
       "0                   0                 0                   0  ...   \n",
       "1                   0                 0                   0  ...   \n",
       "2                   0                 0                   0  ...   \n",
       "3                  25                 0                  24  ...   \n",
       "4                  73                 1                 164  ...   \n",
       "\n",
       "   Female 30-50 years  Male above 50 years  Female above 50 years  Total Male  \\\n",
       "0                   0                    0                      0           3   \n",
       "1                   0                    0                      0           2   \n",
       "2                   0                    0                      0           0   \n",
       "3                   2                    0                      0           0   \n",
       "4                   4                    0                      0           7   \n",
       "\n",
       "   Total Female  Grand Total  Male below 18  Female below 18  \\\n",
       "0             5            8              3                1   \n",
       "1             0            2              2                0   \n",
       "2             0            0              0                0   \n",
       "3            78           78              0               51   \n",
       "4           332          339              1              237   \n",
       "\n",
       "   Number of children  Label  \n",
       "0                   4      F  \n",
       "1                   2      M  \n",
       "2                   0      F  \n",
       "3                  51      F  \n",
       "4                 238      F  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"C:/Users/Vineet Kumar/Downloads/kidnapping.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE/UT</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>Purpose</th>\n",
       "      <th>Male 18-30 years</th>\n",
       "      <th>Female 18-30 years</th>\n",
       "      <th>Male 30-50 years</th>\n",
       "      <th>Female 30-50 years</th>\n",
       "      <th>Male above 50 years</th>\n",
       "      <th>Female above 50 years</th>\n",
       "      <th>Grand Total</th>\n",
       "      <th>Male below 18</th>\n",
       "      <th>Female below 18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>2001</td>\n",
       "      <td>For Adoption</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>2001</td>\n",
       "      <td>For Begging</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>2001</td>\n",
       "      <td>For Camel racing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>2001</td>\n",
       "      <td>For Illicit intercourse</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>2001</td>\n",
       "      <td>For marriage</td>\n",
       "      <td>6</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>339</td>\n",
       "      <td>1</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         STATE/UT  YEAR                  Purpose  Male 18-30 years  \\\n",
       "0  Andhra Pradesh  2001             For Adoption                 0   \n",
       "1  Andhra Pradesh  2001              For Begging                 0   \n",
       "2  Andhra Pradesh  2001         For Camel racing                 0   \n",
       "3  Andhra Pradesh  2001  For Illicit intercourse                 0   \n",
       "4  Andhra Pradesh  2001             For marriage                 6   \n",
       "\n",
       "   Female 18-30 years  Male 30-50 years  Female 30-50 years  \\\n",
       "0                   4                 0                   0   \n",
       "1                   0                 0                   0   \n",
       "2                   0                 0                   0   \n",
       "3                  25                 0                   2   \n",
       "4                  91                 0                   4   \n",
       "\n",
       "   Male above 50 years  Female above 50 years  Grand Total  Male below 18  \\\n",
       "0                    0                      0            8              3   \n",
       "1                    0                      0            2              2   \n",
       "2                    0                      0            0              0   \n",
       "3                    0                      0           78              0   \n",
       "4                    0                      0          339              1   \n",
       "\n",
       "   Female below 18  \n",
       "0                1  \n",
       "1                0  \n",
       "2                0  \n",
       "3               51  \n",
       "4              237  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['Total No. of cases reported'], axis=1)\n",
    "df = df.drop(['Male upto 10 years'], axis=1)\n",
    "df = df.drop(['Female upto 10 years'], axis=1)\n",
    "df = df.drop(['Male 10-15 years'], axis=1)\n",
    "df = df.drop(['Female 10-15 years'], axis=1)\n",
    "df = df.drop(['Male 15-18 years'], axis=1)\n",
    "df = df.drop(['Female 15-18 years'], axis=1)\n",
    "df = df.drop(['Total Male'], axis=1)\n",
    "df = df.drop(['Total Female'], axis=1)\n",
    "df = df.drop(['Number of children'], axis=1)\n",
    "df = df.drop(['Label'], axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      STATE/UT  YEAR  Purpose  Male 18-30 years  Female 18-30 years  \\\n",
      "0            1     0        0                 0                   4   \n",
      "1            1     0        1                 0                   0   \n",
      "2            1     0        2                 0                   0   \n",
      "3            1     0        3                 0                  25   \n",
      "4            1     0       10                 6                  91   \n",
      "5            1     0        4                 0                  16   \n",
      "6            1     0        5                 2                   0   \n",
      "7            1     0        6                11                   4   \n",
      "8            1     0        7                 0                   0   \n",
      "9            1     0        8                 0                   0   \n",
      "10           1     0        9                 0                   0   \n",
      "11           1     0       11                54                  52   \n",
      "12           1     0       13               140                 146   \n",
      "13           1     0       14               182                 255   \n",
      "14           1     1        0                 0                   0   \n",
      "15           1     1        1                 4                   1   \n",
      "16           1     1        2                 0                   0   \n",
      "17           1     1        3                 0                  89   \n",
      "18           1     1       10                 0                 247   \n",
      "19           1     1        4                 0                  49   \n",
      "20           1     1        5                 4                   0   \n",
      "21           1     1        6                 6                  15   \n",
      "22           1     1        7                 0                   1   \n",
      "23           1     1        8                 0                   0   \n",
      "24           1     1        9                 0                   3   \n",
      "25           1     1       11                45                  41   \n",
      "26           1     1       13               190                 164   \n",
      "27           1     1       14               214                 386   \n",
      "28           1     2        0                 0                   0   \n",
      "29           1     2        1                 0                   0   \n",
      "...        ...   ...      ...               ...                 ...   \n",
      "5836        26     9       13                 0                   0   \n",
      "5837        26     9       14                 1                   6   \n",
      "5838        26    10        0                 0                   0   \n",
      "5839        26    10        1                 0                   0   \n",
      "5840        26    10        2                 0                   0   \n",
      "5841        26    10        3                 0                   1   \n",
      "5842        26    10       10                 0                   0   \n",
      "5843        26    10        4                 0                   0   \n",
      "5844        26    10        5                 0                   0   \n",
      "5845        26    10        6                 0                   0   \n",
      "5846        26    10        7                 0                   0   \n",
      "5847        26    10        8                 0                   0   \n",
      "5848        26    10        9                 0                   0   \n",
      "5849        26    10       11                 1                   1   \n",
      "5850        26    10       13                 0                   0   \n",
      "5851        26    10       14                 1                   2   \n",
      "5852        26    11        0                 0                   0   \n",
      "5853        26    11        1                 0                   0   \n",
      "5854        26    11        2                 0                   0   \n",
      "5855        26    11        3                 0                   0   \n",
      "5856        26    11       10                 0                   1   \n",
      "5857        26    11        4                 0                   0   \n",
      "5858        26    11        5                 0                   0   \n",
      "5859        26    11        6                 0                   0   \n",
      "5860        26    11        7                 0                   0   \n",
      "5861        26    11        8                 0                   0   \n",
      "5862        26    11        9                 0                   0   \n",
      "5863        26    11       11                 0                   0   \n",
      "5864        26    11       13                 0                   0   \n",
      "5865        26    11       14                 0                   1   \n",
      "\n",
      "      Male 30-50 years  Female 30-50 years  Male above 50 years  \\\n",
      "0                    0                   0                    0   \n",
      "1                    0                   0                    0   \n",
      "2                    0                   0                    0   \n",
      "3                    0                   2                    0   \n",
      "4                    0                   4                    0   \n",
      "5                    0                   2                    0   \n",
      "6                    1                   0                    0   \n",
      "7                   12                   1                    0   \n",
      "8                    0                   0                    0   \n",
      "9                    0                   0                    0   \n",
      "10                   0                   0                    0   \n",
      "11                  26                   5                    2   \n",
      "12                  80                  11                    3   \n",
      "13                 114                  25                    5   \n",
      "14                   0                   0                    0   \n",
      "15                   0                   0                    0   \n",
      "16                   0                   0                    0   \n",
      "17                   0                   8                    0   \n",
      "18                   3                   4                    0   \n",
      "19                   0                   5                    0   \n",
      "20                   1                   0                    0   \n",
      "21                   2                   2                    3   \n",
      "22                   0                   0                    0   \n",
      "23                   0                   0                    0   \n",
      "24                   0                   0                    0   \n",
      "25                  11                   5                    6   \n",
      "26                 104                  27                    4   \n",
      "27                 118                  51                   13   \n",
      "28                   0                   0                    0   \n",
      "29                   0                   0                    0   \n",
      "...                ...                 ...                  ...   \n",
      "5836                 0                   0                    0   \n",
      "5837                 1                   0                    0   \n",
      "5838                 0                   0                    0   \n",
      "5839                 0                   0                    0   \n",
      "5840                 0                   0                    0   \n",
      "5841                 0                   0                    0   \n",
      "5842                 0                   0                    0   \n",
      "5843                 0                   0                    0   \n",
      "5844                 0                   0                    0   \n",
      "5845                 0                   0                    0   \n",
      "5846                 0                   0                    0   \n",
      "5847                 0                   0                    0   \n",
      "5848                 0                   0                    0   \n",
      "5849                 1                   1                    0   \n",
      "5850                 0                   0                    0   \n",
      "5851                 1                   1                    0   \n",
      "5852                 0                   0                    0   \n",
      "5853                 0                   0                    0   \n",
      "5854                 0                   0                    0   \n",
      "5855                 0                   0                    0   \n",
      "5856                 0                   0                    0   \n",
      "5857                 0                   0                    0   \n",
      "5858                 0                   0                    0   \n",
      "5859                 0                   0                    0   \n",
      "5860                 0                   0                    0   \n",
      "5861                 0                   0                    0   \n",
      "5862                 0                   0                    0   \n",
      "5863                 0                   0                    0   \n",
      "5864                 0                   0                    0   \n",
      "5865                 0                   0                    0   \n",
      "\n",
      "      Female above 50 years  Grand Total  Male below 18  Female below 18  \n",
      "0                         0            8              3                1  \n",
      "1                         0            2              2                0  \n",
      "2                         0            0              0                0  \n",
      "3                         0           78              0               51  \n",
      "4                         0          278              1              179  \n",
      "5                         0           36              0               18  \n",
      "6                         0           13              7                3  \n",
      "7                         0           47             11                8  \n",
      "8                         0            0              0                0  \n",
      "9                         0            0              0                0  \n",
      "10                        0            0              0                0  \n",
      "11                        0          164             23                6  \n",
      "12                        0          358             45               52  \n",
      "13                        0          552             86              229  \n",
      "14                        0            0              0                0  \n",
      "15                        0            6              1                0  \n",
      "16                        0            0              0                0  \n",
      "17                        0           98              0                1  \n",
      "18                        0          302              0               48  \n",
      "19                        0           61              0                7  \n",
      "20                        0            8              2                1  \n",
      "21                        0           34              4                2  \n",
      "22                        0            3              1                1  \n",
      "23                        0            0              0                0  \n",
      "24                        0            3              0                0  \n",
      "25                        0          107              0                0  \n",
      "26                        9          386              5               13  \n",
      "27                        9          571             13               72  \n",
      "28                        0            0              0                0  \n",
      "29                        0            1              0                1  \n",
      "...                     ...          ...            ...              ...  \n",
      "5836                      0            0              0                0  \n",
      "5837                      0           20              2               10  \n",
      "5838                      0            0              0                0  \n",
      "5839                      0            0              0                0  \n",
      "5840                      0            0              0                0  \n",
      "5841                      0            1              0                0  \n",
      "5842                      0            5              0                5  \n",
      "5843                      0            0              0                0  \n",
      "5844                      0            1              1                0  \n",
      "5845                      0            0              0                0  \n",
      "5846                      0            0              0                0  \n",
      "5847                      0            0              0                0  \n",
      "5848                      0            0              0                0  \n",
      "5849                      0            5              0                1  \n",
      "5850                      0            0              0                0  \n",
      "5851                      0           12              1                6  \n",
      "5852                      0            0              0                0  \n",
      "5853                      0            0              0                0  \n",
      "5854                      0            0              0                0  \n",
      "5855                      0            0              0                0  \n",
      "5856                      0           11              0               10  \n",
      "5857                      0            0              0                0  \n",
      "5858                      0            0              0                0  \n",
      "5859                      0            0              0                0  \n",
      "5860                      0            0              0                0  \n",
      "5861                      0            0              0                0  \n",
      "5862                      0            0              0                0  \n",
      "5863                      0            0              0                0  \n",
      "5864                      0            8              3                5  \n",
      "5865                      0           19              3               15  \n",
      "\n",
      "[5866 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def encode_df(dataframe):\n",
    "    le = LabelEncoder()\n",
    "    for column in dataframe.columns:\n",
    "        dataframe[column] = le.fit_transform(dataframe[column])\n",
    "    return dataframe\n",
    "\n",
    "#encode the dataframe\n",
    "data=encode_df(df)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, df.columns != '2']\n",
    "#X = df.iloc[:, 0:4].values \n",
    "y = df.iloc[:, 2].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vineet Kumar\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int32, int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Vineet Kumar\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int32, int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "C:\\Users\\Vineet Kumar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int32, int64 were all converted to float64 by StandardScaler.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()  \n",
    "X_train = sc.fit_transform(X_train)  \n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "classifier = RandomForestClassifier(n_estimators=100, random_state=0) \n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "classifier.fit(X_train, y_train)  \n",
    "y_pred = classifier.predict(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[90  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 72  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 89  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 91  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 87  1  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0 67  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 84  1  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  2 86  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  1 82  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  0  0 86  0  1  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  1 80  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  2 70  0  1]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  1  2 93  1]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  2 77]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        90\n",
      "           1       1.00      1.00      1.00        72\n",
      "           2       1.00      1.00      1.00        89\n",
      "           3       0.99      1.00      0.99        91\n",
      "           4       1.00      0.98      0.99        89\n",
      "           5       0.99      0.97      0.98        69\n",
      "           6       0.94      0.99      0.97        85\n",
      "           7       0.98      0.98      0.98        88\n",
      "           8       1.00      0.99      0.99        83\n",
      "           9       0.99      0.98      0.98        88\n",
      "          10       0.96      0.99      0.98        81\n",
      "          11       0.96      0.96      0.96        73\n",
      "          13       0.98      0.96      0.97        97\n",
      "          14       0.97      0.97      0.97        79\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1174\n",
      "   macro avg       0.98      0.98      0.98      1174\n",
      "weighted avg       0.98      0.98      0.98      1174\n",
      "\n",
      "0.9829642248722317\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred)) \n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.6, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vineet Kumar\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int32, int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Vineet Kumar\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int32, int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "C:\\Users\\Vineet Kumar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int32, int64 were all converted to float64 by StandardScaler.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()  \n",
    "X_train = sc.fit_transform(X_train)  \n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "classifier = RandomForestClassifier(n_estimators=100, random_state=0) \n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "classifier.fit(X_train, y_train)  \n",
    "y_pred = classifier.predict(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[248   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  1 242   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0 260   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0 246   3   1   0   0   0   0   1   0   0   0]\n",
      " [  0   0   0   2 247   7   1   0   0   0   0   0   0   0]\n",
      " [  0   0   0   1   2 236  13   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   2 218   4   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  11 255   1   1   3   0   1   0]\n",
      " [  0   0   0   0   0   0   1   2 260   0   1   0   0   0]\n",
      " [  0   0   0   0   0   0   2   3   1 238   2   4   0   0]\n",
      " [  0   0   0   0   2   0   0   1   0   3 247   0   0   0]\n",
      " [  0   0   0   0   0   0   0   1   0   2   5 222   7   1]\n",
      " [  0   0   0   0   0   0   0   0   0   1   4  16 231   6]\n",
      " [  0   0   0   0   0   0   0   0   0   0   1  10   8 231]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       248\n",
      "           1       1.00      1.00      1.00       243\n",
      "           2       1.00      1.00      1.00       260\n",
      "           3       0.99      0.98      0.98       251\n",
      "           4       0.97      0.96      0.97       257\n",
      "           5       0.96      0.94      0.95       252\n",
      "           6       0.89      0.97      0.93       224\n",
      "           7       0.96      0.94      0.95       272\n",
      "           8       0.99      0.98      0.99       264\n",
      "           9       0.97      0.95      0.96       250\n",
      "          10       0.94      0.98      0.96       253\n",
      "          11       0.88      0.93      0.91       238\n",
      "          13       0.94      0.90      0.91       258\n",
      "          14       0.97      0.92      0.95       250\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      3520\n",
      "   macro avg       0.96      0.96      0.96      3520\n",
      "weighted avg       0.96      0.96      0.96      3520\n",
      "\n",
      "0.9605113636363637\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred)) \n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vineet Kumar\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int32, int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Vineet Kumar\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int32, int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "C:\\Users\\Vineet Kumar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int32, int64 were all converted to float64 by StandardScaler.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()  \n",
    "X_train = sc.fit_transform(X_train)  \n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "classifier = RandomForestClassifier(n_estimators=100, random_state=0) \n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "classifier.fit(X_train, y_train)  \n",
    "y_pred = classifier.predict(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[293   0   0   0   0   3   0   0   0   0   0   0   0   0]\n",
      " [  1 274   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0 306   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0 293   6   2   0   0   0   0   1   0   0   0]\n",
      " [  0   0   0   7 275   8   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   2   5 278   4   0   0   0   0   1   0   0]\n",
      " [  0   0   0   0   1   3 268   5   0   0   0   1   0   0]\n",
      " [  0   0   0   1   1   0  14 286   1   0   2   0   1   0]\n",
      " [  0   0   0   0   0   0   3   0 305   0   1   0   0   0]\n",
      " [  0   0   0   0   0   0   2   1   1 275   3   8   1   0]\n",
      " [  0   0   0   0   0   0   0   2   0   2 284   0   1   0]\n",
      " [  0   0   0   0   0   0   0   0   0   2   6 266   7   1]\n",
      " [  0   0   0   0   0   0   0   0   0   3   2  23 262   7]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11  10 275]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       296\n",
      "           1       1.00      1.00      1.00       275\n",
      "           2       1.00      1.00      1.00       306\n",
      "           3       0.97      0.97      0.97       302\n",
      "           4       0.95      0.95      0.95       290\n",
      "           5       0.95      0.96      0.95       290\n",
      "           6       0.92      0.96      0.94       278\n",
      "           7       0.97      0.93      0.95       306\n",
      "           8       0.99      0.99      0.99       309\n",
      "           9       0.98      0.95      0.96       291\n",
      "          10       0.95      0.98      0.97       289\n",
      "          11       0.86      0.94      0.90       282\n",
      "          13       0.93      0.88      0.91       297\n",
      "          14       0.97      0.93      0.95       296\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      4107\n",
      "   macro avg       0.96      0.96      0.96      4107\n",
      "weighted avg       0.96      0.96      0.96      4107\n",
      "\n",
      "0.9593377160944728\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred)) \n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.8, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vineet Kumar\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int32, int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Vineet Kumar\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int32, int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "C:\\Users\\Vineet Kumar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int32, int64 were all converted to float64 by StandardScaler.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()  \n",
    "X_train = sc.fit_transform(X_train)  \n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "classifier = RandomForestClassifier(n_estimators=100, random_state=0) \n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "classifier.fit(X_train, y_train)  \n",
    "y_pred = classifier.predict(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[330   0   0   1   0   2   0   0   0   0   0   0   0   0]\n",
      " [  2 327   0   2   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0 349   3   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   2 320  15   1   0   0   0   0   1   0   0   0]\n",
      " [  0   0   0  19 302  10   0   0   0   0   3   0   0   0]\n",
      " [  0   0   0   6  15 294   8   1   0   1   0   1   1   0]\n",
      " [  0   0   0   1   3   7 308   9   0   0   0   1   0   0]\n",
      " [  0   0   0   1   2   0  23 316   1   2   3   0   1   0]\n",
      " [  0   0   0   0   0   0   2   0 335   0   2   0   0   0]\n",
      " [  0   0   0   0   0   0   8   0   1 308   4  14   1   0]\n",
      " [  0   0   0   0   0   0   0   0   0   6 326   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0   0   2   9 304   6   0]\n",
      " [  0   0   0   0   0   0   0   1   0   2   5  28 294   8]\n",
      " [  0   0   0   0   0   0   0   0   0   0   1  12   6 313]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       333\n",
      "           1       1.00      0.99      0.99       331\n",
      "           2       0.99      0.99      0.99       352\n",
      "           3       0.91      0.94      0.92       339\n",
      "           4       0.90      0.90      0.90       334\n",
      "           5       0.93      0.90      0.92       327\n",
      "           6       0.88      0.94      0.91       329\n",
      "           7       0.97      0.91      0.93       349\n",
      "           8       0.99      0.99      0.99       339\n",
      "           9       0.96      0.92      0.94       336\n",
      "          10       0.92      0.98      0.95       332\n",
      "          11       0.84      0.94      0.89       322\n",
      "          13       0.95      0.87      0.91       338\n",
      "          14       0.98      0.94      0.96       332\n",
      "\n",
      "   micro avg       0.94      0.94      0.94      4693\n",
      "   macro avg       0.94      0.94      0.94      4693\n",
      "weighted avg       0.94      0.94      0.94      4693\n",
      "\n",
      "0.9431067547411037\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred)) \n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.9, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vineet Kumar\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int32, int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Vineet Kumar\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int32, int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "C:\\Users\\Vineet Kumar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int32, int64 were all converted to float64 by StandardScaler.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()  \n",
    "X_train = sc.fit_transform(X_train)  \n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "classifier = RandomForestClassifier(n_estimators=100, random_state=0) \n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "classifier.fit(X_train, y_train)  \n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[375   0   0   3   0   5   0   0   0   0   0   0   0   0]\n",
      " [ 20 352   0   2   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0 382   4   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0  21 323  25   2   0   0   0   0   5   0   0   0]\n",
      " [  0   0   0  44 323   8   0   0   0   0   3   0   0   0]\n",
      " [  1   0   0   7   7 317  31   6   0   0   0   1   3   0]\n",
      " [  0   0   0   0   6  23 316  18   0   0   0   1   3   0]\n",
      " [  0   0   0   1  12   3  41 280  32   2  17   0   1   0]\n",
      " [  0   0   0   0   0   0   1   4 373   0   3   0   0   0]\n",
      " [  0   0   0   0   0   0  17   1   1 343   5  12   0   0]\n",
      " [  0   0   0   0   0   0   3   0   0   0 352  15   3   0]\n",
      " [  0   0   0   0   0   0   1   0   2   2  13 336  17   0]\n",
      " [  0   0   0   0   0   0   0   0   1   2  11  42 320   6]\n",
      " [  0   0   0   0   0   0   0   0   0   0   4   8   0 356]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96       383\n",
      "           1       1.00      0.94      0.97       374\n",
      "           2       0.95      0.99      0.97       386\n",
      "           3       0.84      0.86      0.85       376\n",
      "           4       0.87      0.85      0.86       378\n",
      "           5       0.89      0.85      0.87       373\n",
      "           6       0.77      0.86      0.81       367\n",
      "           7       0.91      0.72      0.80       389\n",
      "           8       0.91      0.98      0.94       381\n",
      "           9       0.98      0.91      0.94       379\n",
      "          10       0.85      0.94      0.90       373\n",
      "          11       0.81      0.91      0.85       371\n",
      "          13       0.92      0.84      0.88       382\n",
      "          14       0.98      0.97      0.98       368\n",
      "\n",
      "   micro avg       0.90      0.90      0.90      5280\n",
      "   macro avg       0.90      0.90      0.90      5280\n",
      "weighted avg       0.90      0.90      0.90      5280\n",
      "\n",
      "0.8992424242424243\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred)) \n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# data to plot\n",
    "n_groups =5 \n",
    "accuracy1=98.29\n",
    "accuracy2=96.05\n",
    "accuracy3=95.93\n",
    "accuracy4=94.31\n",
    "accuracy5=89.92\n",
    "\n",
    "means_accuracy=(accuracy1,accuracy2,accuracy3,accuracy4,accuracy5)\n",
    " \n",
    "# create plot\n",
    "fig, ax = plt.subplots()\n",
    "index = np.arange(n_groups)\n",
    "bar_width = 0.40\n",
    "opacity = 0.8\n",
    " \n",
    "sns.set_color_codes(\"pastel\")\n",
    "rects1 = plt.bar(index, means_accuracy, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 label='Accuracy')\n",
    "  \n",
    "plt.xlabel('Ratio of test and train data')\n",
    "plt.ylabel('Values')\n",
    "plt.title('Accuracy of Random Forest')\n",
    "plt.xticks(index, ('50:50', '60:40', '70:30','80:20','90:10'))\n",
    "plt.legend()\n",
    " \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
